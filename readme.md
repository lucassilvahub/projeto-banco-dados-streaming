# Plataforma de Streaming com Polyglot Persistence

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa uma plataforma de streaming moderna com arquitetura orientada a eventos e persistÃªncia poliglota (utilizando diferentes bancos de dados para diferentes tipos de dados). A aplicaÃ§Ã£o Ã© construÃ­da como um sistema distribuÃ­do baseado em microserviÃ§os, com comunicaÃ§Ã£o assÃ­ncrona via Kafka.

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por 3 serviÃ§os principais e um dashboard, todos containerizados via Docker:

```mermaid
graph TD
    Client[Cliente HTTP] -->|RequisiÃ§Ãµes| S1[S1 - API FastAPI]
    S1 -->|Produz eventos| Kafka[Apache Kafka]
    Kafka -->|Consome eventos| S2[S2 - Processador]
    S2 -->|Armazena dados| Postgres[(PostgreSQL)]
    S2 -->|Produz respostas| Kafka
    Kafka -->|Respostas| S1
    Kafka -->|Eventos/Respostas| S3[S3 - Monitor]
    S3 -->|Armazena logs| ES[(Elasticsearch)]
    ES -->|VisualizaÃ§Ã£o| Kibana[Kibana]
    
    Client -->|Acesso| Dashboard[Dashboard Web]
    Dashboard -->|Links| Adminer[Adminer]
    Dashboard -->|Links| KafkaUI[Kafka UI]
    Dashboard -->|Links| Kibana
    Dashboard -->|Links| SwaggerUI[Swagger UI]
    
    classDef primary fill:#3498db,stroke:#2980b9,color:white;
    classDef secondary fill:#2ecc71,stroke:#27ae60,color:white;
    classDef database fill:#e74c3c,stroke:#c0392b,color:white;
    classDef queue fill:#f39c12,stroke:#d35400,color:white;
    classDef ui fill:#9b59b6,stroke:#8e44ad,color:white;
    
    class S1,S2,S3 primary;
    class Postgres,ES,MongoDB,Redis database;
    class Kafka queue;
    class Dashboard,Adminer,KafkaUI,Kibana,SwaggerUI ui;
    class Client secondary;
```

### ServiÃ§os

1. **S1 (API)**: ServiÃ§o de API RESTful desenvolvido com FastAPI, responsÃ¡vel por:
   - Receber requisiÃ§Ãµes HTTP
   - Gerar eventos para o Kafka
   - Acompanhar o status das operaÃ§Ãµes via correlation_id
   - Expor endpoints para gerenciamento de usuÃ¡rios, assinaturas e pagamentos

2. **S2 (Processador)**: ServiÃ§o de processamento de eventos, responsÃ¡vel por:
   - Consumir eventos do Kafka
   - Persistir os dados no PostgreSQL
   - Processar operaÃ§Ãµes de negÃ³cio
   - Enviar respostas via Kafka

3. **S3 (Monitor)**: ServiÃ§o de monitoramento e logging, responsÃ¡vel por:
   - Consumir eventos de todos os tÃ³picos do Kafka
   - Armazenar logs no Elasticsearch
   - Monitorar fluxos de requisiÃ§Ãµes e respostas
   - Fornecer fallback para logs em arquivo quando Elasticsearch nÃ£o estiver disponÃ­vel

4. **Dashboard**: Interface web simples para visualizaÃ§Ã£o e acesso a todos os componentes da plataforma

### Bancos de Dados

O sistema utiliza persistÃªncia poliglota:

- **PostgreSQL**: Armazena dados relacionais de usuÃ¡rios, assinaturas e pagamentos
- **MongoDB**: Disponibilizado para dados nÃ£o estruturados (nÃ£o utilizado na versÃ£o atual)
- **Redis**: Disponibilizado para caching (nÃ£o utilizado na versÃ£o atual)
- **Elasticsearch**: Armazena logs de sistema para anÃ¡lise e monitoramento

### Ferramentas de AdministraÃ§Ã£o

- **Adminer**: AdministraÃ§Ã£o do PostgreSQL
- **Kafka UI**: VisualizaÃ§Ã£o e administraÃ§Ã£o dos tÃ³picos Kafka
- **Kibana**: VisualizaÃ§Ã£o e anÃ¡lise dos logs no Elasticsearch

### Fluxo de Dados

A comunicaÃ§Ã£o entre os serviÃ§os segue o padrÃ£o 

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker
- Docker Compose
- Python 3.x (para o script de inicializaÃ§Ã£o)

### Passos de InicializaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone [URL_DO_REPOSITORIO]
cd [NOME_DO_DIRETORIO]
```

2. Execute o script de inicializaÃ§Ã£o:
```bash
python start.py
```

O script `start.py` vai:
- Verificar se Docker e Docker Compose estÃ£o instalados
- Verificar e criar a estrutura de diretÃ³rios necessÃ¡ria
- Parar os containers existentes (se houver)
- Iniciar os containers via Docker Compose
- Abrir o dashboard no navegador

3. ApÃ³s a inicializaÃ§Ã£o, o dashboard estarÃ¡ disponÃ­vel em:
```
http://localhost:8089
```

### Portas Utilizadas

- **8000**: API principal (S1)
- **8089**: Dashboard
- **8080**: Kafka UI
- **8081**: Adminer (AdministraÃ§Ã£o PostgreSQL)
- **5601**: Kibana
- **9200**: Elasticsearch
- **5432**: PostgreSQL
- **27017**: MongoDB
- **6379**: Redis

## ğŸ”§ Estrutura do Projeto

```
.
â”œâ”€â”€ .env                  # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore            # Arquivos ignorados pelo git
â”œâ”€â”€ docker-compose.yaml   # ConfiguraÃ§Ã£o dos containers Docker
â”œâ”€â”€ start.py              # Script de inicializaÃ§Ã£o
â”œâ”€â”€ s1/                   # ServiÃ§o API (FastAPI)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py
â”œâ”€â”€ s2/                   # ServiÃ§o Processador
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py
â”œâ”€â”€ s3/                   # ServiÃ§o Monitor
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py
â””â”€â”€ dashboard/            # Interface Web
    â””â”€â”€ html/
        â”œâ”€â”€ index.html
        â””â”€â”€ style.css
```

## ğŸ“ Como Testar

1. **Acessar o Dashboard:**
   - Abra http://localhost:8089 no navegador
   - Use os links para navegar entre os diferentes componentes

2. **Testar a API (Swagger UI):**
   - Acesse http://localhost:8000/docs
   - Utilize a documentaÃ§Ã£o interativa para testar os endpoints

3. **Endpoints Principais:**
   - `POST /usuarios` - Criar um novo usuÃ¡rio
   - `POST /usuarios/{id}/assinatura` - Criar uma assinatura para um usuÃ¡rio
   - `POST /usuarios/{id}/pagamento` - Registrar um pagamento para um usuÃ¡rio
   - `POST /usuarios/{id}/config` - Atualizar configuraÃ§Ãµes de um usuÃ¡rio
   - `GET /status/{correlation_id}` - Verificar o status de uma operaÃ§Ã£o
   - `GET /health` - Verificar a saÃºde do serviÃ§o

4. **Visualizar Logs:**
   - Use o Kibana em http://localhost:5601 para visualizar os logs no Elasticsearch
   - Configure um index pattern para "system_logs" na primeira vez

5. **Monitorar TÃ³picos Kafka:**
   - Acesse http://localhost:8080 para visualizar os tÃ³picos e mensagens no Kafka

## ğŸ“Š TÃ³picos Kafka

- **user_events**: Eventos relacionados aos usuÃ¡rios (criaÃ§Ã£o, atualizaÃ§Ã£o, etc.)
- **response_events**: Respostas do processamento de eventos

## ğŸ—ƒï¸ Tabelas PostgreSQL

- **usuarios**: Armazena informaÃ§Ãµes dos usuÃ¡rios
- **assinaturas**: Armazena dados de assinaturas
- **pagamentos**: Registra pagamentos realizados
- **preferencias**: Armazena preferÃªncias e configuraÃ§Ãµes dos usuÃ¡rios

## ğŸ§° Tecnologias Utilizadas

- **Backend**: Python 3.11
- **API**: FastAPI
- **Processamento AssÃ­ncrono**: asyncio, aiokafka
- **Banco de Dados**: PostgreSQL, MongoDB, Redis, Elasticsearch
- **Mensageria**: Kafka
- **Frontend**: HTML, CSS
- **ContainerizaÃ§Ã£o**: Docker, Docker Compose
- **Monitoramento**: Kibana, Kafka UI, Adminer

## ğŸ“ˆ Escalabilidade e Melhorias Futuras

O sistema foi projetado para ser escalÃ¡vel:

1. **Escalabilidade Horizontal**:
   - Todos os serviÃ§os podem ser replicados para aumentar a capacidade
   - Kafka gerencia o balanceamento das mensagens entre instÃ¢ncias

2. **PossÃ­veis Melhorias**:
   - Implementar autenticaÃ§Ã£o e autorizaÃ§Ã£o
   - Adicionar monitoramento com Prometheus e Grafana
   - Expandir o uso dos demais bancos de dados (MongoDB e Redis)
   - Implementar testes automatizados
   - Adicionar CI/CD pipeline
   - Implementar serviÃ§o de recomendaÃ§Ã£o baseado em histÃ³rico de visualizaÃ§Ã£o

## âš ï¸ SoluÃ§Ã£o de Problemas

- **Erro ao iniciar os containers:** Verifique se as portas necessÃ¡rias nÃ£o estÃ£o em uso por outros aplicativos
- **S1 nÃ£o conecta ao Kafka:** O serviÃ§o tentarÃ¡ reconectar automaticamente. Se persistir, reinicie o container
- **S2 nÃ£o conecta ao PostgreSQL:** Verifique os logs e certifique-se de que as variÃ¡veis de ambiente estÃ£o corretas
- **Dashboard nÃ£o carrega:** Verifique se o container do Nginx estÃ¡ em execuÃ§Ã£o

Para interromper todos os serviÃ§os:
```bash
docker-compose down
```

Para visualizar logs de um serviÃ§o especÃ­fico:
```bash
docker logs [nome_do_container]
```

## ğŸ§© Detalhes TÃ©cnicos

### ComunicaÃ§Ã£o AssÃ­ncrona

O sistema utiliza o padrÃ£o de correlation_id para rastrear o fluxo de mensagens:

1. S1 gera um UUID Ãºnico (correlation_id) para cada operaÃ§Ã£o
2. O correlation_id Ã© enviado junto com o evento para o Kafka
3. S2 processa o evento e envia uma resposta com o mesmo correlation_id
4. S1 armazena as respostas em um dicionÃ¡rio indexado pelo correlation_id
5. Clientes podem consultar o status via endpoint `/status/{correlation_id}`

### ResiliÃªncia

O sistema foi projetado para ser resiliente:

- **Reconnection**: ServiÃ§os tentam reconectar automaticamente ao Kafka e PostgreSQL
- **Fallback para Logs**: S3 usa um arquivo local como fallback quando Elasticsearch nÃ£o estÃ¡ disponÃ­vel
- **Containers Resilientes**: ConfiguraÃ§Ã£o `restart: on-failure` garante que os containers sejam reiniciados em caso de falha