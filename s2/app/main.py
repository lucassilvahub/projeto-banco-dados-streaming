import asyncio
import json
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from datetime import datetime
import logging
import os
import time
import sys
from aiohttp import web

# Importar handlers para os diferentes bancos de dados
# Handlers foram modificados para evitar importa√ß√£o circular
import postgres_handler
import mongodb_handler
import redis_handler

# ========================
# üõ†Ô∏è Configura√ß√µes
# ========================
KAFKA_BROKER = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092")
INPUT_TOPIC = "user_events"
OUTPUT_TOPIC = "response_events"
KAFKA_CONSUMER_TIMEOUT_MS = int(os.getenv("KAFKA_CONSUMER_TIMEOUT_MS", "30000"))

# ========================
# üì• Configura√ß√£o de Logs
# ========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("s2_main")

# ========================
# üîÑ Fun√ß√µes Utilit√°rias do Kafka
# ========================
async def create_kafka_producer(max_retries=15, retry_delay=5):
    """Inicia o produtor Kafka com v√°rias tentativas."""
    producer = None
    retries = 0
    
    while producer is None and retries < max_retries:
        try:
            logger.info(f"üîå Iniciando Kafka Producer... ({retries+1}/{max_retries})")
            producer = AIOKafkaProducer(
                bootstrap_servers=KAFKA_BROKER,
                value_serializer=lambda v: json.dumps(v).encode("utf-8")
            )
            await producer.start()
            logger.info("‚úÖ Kafka Producer iniciado com sucesso!")
            return producer
        except Exception as e:
            logger.error(f"‚ùå Erro ao iniciar Kafka Producer: {e}")
            retries += 1
            await asyncio.sleep(retry_delay)
    
    if producer is None:
        logger.error("‚ùå N√£o foi poss√≠vel iniciar o Kafka Producer ap√≥s v√°rias tentativas.")
        return None

async def create_kafka_consumer(max_retries=15, retry_delay=5):
    """Inicia o consumidor Kafka com v√°rias tentativas."""
    consumer = None
    retries = 0
    
    while consumer is None and retries < max_retries:
        try:
            logger.info(f"üîå Iniciando Kafka Consumer... ({retries+1}/{max_retries})")
            consumer = AIOKafkaConsumer(
                INPUT_TOPIC,
                bootstrap_servers=KAFKA_BROKER,
                group_id="s2_consumer_group",
                value_deserializer=lambda m: json.loads(m.decode("utf-8")),
                auto_offset_reset="latest",
                consumer_timeout_ms=KAFKA_CONSUMER_TIMEOUT_MS
            )
            await consumer.start()
            logger.info("‚úÖ Kafka Consumer iniciado com sucesso!")
            
            # Verificar se o t√≥pico existe
            topics = await consumer.topics()
            if INPUT_TOPIC not in topics:
                logger.warning(f"‚ö†Ô∏è T√≥pico {INPUT_TOPIC} n√£o encontrado. Tentando criar...")
                # Tenta enviar uma mensagem para criar o t√≥pico
                temp_producer = AIOKafkaProducer(
                    bootstrap_servers=KAFKA_BROKER,
                    value_serializer=lambda v: json.dumps(v).encode("utf-8")
                )
                await temp_producer.start()
                await temp_producer.send_and_wait(
                    INPUT_TOPIC, 
                    {"event_type": "init", "message": "Inicializando t√≥pico"}
                )
                await temp_producer.stop()
                logger.info(f"‚úÖ T√≥pico {INPUT_TOPIC} criado com sucesso!")
            else:
                logger.info(f"‚úÖ T√≥pico {INPUT_TOPIC} encontrado!")
                
            # Verificar se o t√≥pico de resposta existe
            if OUTPUT_TOPIC not in topics:
                logger.warning(f"‚ö†Ô∏è T√≥pico {OUTPUT_TOPIC} n√£o encontrado. Tentando criar...")
                # Tenta enviar uma mensagem para criar o t√≥pico
                temp_producer = AIOKafkaProducer(
                    bootstrap_servers=KAFKA_BROKER,
                    value_serializer=lambda v: json.dumps(v).encode("utf-8")
                )
                await temp_producer.start()
                await temp_producer.send_and_wait(
                    OUTPUT_TOPIC, 
                    {"event_type": "init", "message": "Inicializando t√≥pico de resposta"}
                )
                await temp_producer.stop()
                logger.info(f"‚úÖ T√≥pico {OUTPUT_TOPIC} criado com sucesso!")
            else:
                logger.info(f"‚úÖ T√≥pico {OUTPUT_TOPIC} encontrado!")
                
            return consumer
        except Exception as e:
            logger.error(f"‚ùå Erro ao iniciar Kafka Consumer: {e}")
            retries += 1
            await asyncio.sleep(retry_delay)
    
    if consumer is None:
        logger.error("‚ùå N√£o foi poss√≠vel iniciar o Kafka Consumer ap√≥s v√°rias tentativas.")
        return None

# ========================
# üì° Processador Principal
# ========================
async def processar_evento(evento, pg_conn, mongo_db, redis_conn, producer):
    """Roteia eventos para o handler apropriado com base no tipo de evento."""
    tipo = evento.get("event_type")
    correlation_id = evento.get("correlation_id", "unknown")
    
    logger.info(f"üîÑ Processando evento: {tipo} (correlation_id: {correlation_id})")
    
    try:
        # Tentar processar com o handler PostgreSQL primeiro
        if pg_conn is not None:
            result = await postgres_handler.processar_evento_postgres(pg_conn, evento, producer)
            if result is not None:
                return result
        
        # Se n√£o foi processado pelo PostgreSQL, tentar com MongoDB
        if mongo_db is not None:
            result = await mongodb_handler.processar_evento_mongodb(mongo_db, evento, producer)
            if result is not None:
                return result
        
        # Se ainda n√£o foi processado, tentar com Redis
        if redis_conn is not None:
            result = await redis_handler.processar_evento_redis(redis_conn, evento, producer)
            if result is not None:
                return result
        
        # Se nenhum handler processou o evento
        logger.warning(f"‚ö†Ô∏è Evento n√£o reconhecido ou n√£o suportado: {tipo}")
        
        # Enviar resposta de erro para eventos n√£o reconhecidos
        error_response = {
            "correlation_id": correlation_id,
            "event_type": "response",
            "original_event_type": tipo,
            "timestamp": datetime.utcnow().isoformat(),
            "status": "error",
            "message": f"Tipo de evento n√£o suportado: {tipo}"
        }
        
        await producer.send_and_wait(OUTPUT_TOPIC, error_response)
        return False
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao processar evento {tipo}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        
        # Enviar resposta de erro gen√©rica
        error_response = {
            "correlation_id": correlation_id,
            "event_type": "response",
            "original_event_type": tipo,
            "timestamp": datetime.utcnow().isoformat(),
            "status": "error",
            "message": f"Erro ao processar evento: {str(e)}"
        }
        
        await producer.send_and_wait(OUTPUT_TOPIC, error_response)
        return False

async def iniciar_processador():
    """Inicializa o servi√ßo de processamento de eventos com todos os handlers"""
    # Esperando para os servi√ßos estarem prontos
    logger.info("‚è≥ Aguardando servi√ßos estarem dispon√≠veis...")
    await asyncio.sleep(10)
    
    # Inicializar conex√µes com PostgreSQL
    logger.info("üîÑ Inicializando conex√£o com PostgreSQL...")
    pg_conn = await postgres_handler.connect_to_postgres()
    
    # Inicializar conex√µes com MongoDB
    logger.info("üîÑ Inicializando conex√£o com MongoDB...")
    mongo_client, mongo_db = await mongodb_handler.connect_to_mongodb()
    
    # Inicializar conex√µes com Redis
    logger.info("üîÑ Inicializando conex√£o com Redis...")
    redis_conn = await redis_handler.connect_to_redis()
    
    # Verificar se pelo menos um banco de dados est√° dispon√≠vel
    if pg_conn is None and redis_conn is None and mongo_db is None:
        logger.error("‚ùå Nenhum banco de dados dispon√≠vel. Encerrando servi√ßo.")
        return
    
    # Configurar databases dispon√≠veis
    if pg_conn is not None:
        # Inicializar tabelas PostgreSQL
        await postgres_handler.criar_tabelas_postgres(pg_conn)
    
    if redis_conn is not None:
        # Inicializar Redis
        await redis_handler.inicializar_redis(redis_conn)
        
    if mongo_db is not None:
        # Inicializar MongoDB
        await mongodb_handler.inicializar_mongodb(mongo_db)
    
    # Inicializa√ß√£o do produtor Kafka
    producer = await create_kafka_producer()
    if producer is None:
        logger.error("‚ùå N√£o foi poss√≠vel iniciar o produtor Kafka. Encerrando servi√ßo.")
        await cleanup_connections(pg_conn, mongo_client, redis_conn)
        return
    
    # Inicializa√ß√£o do consumidor Kafka
    consumer = await create_kafka_consumer()
    if consumer is None:
        logger.error("‚ùå N√£o foi poss√≠vel iniciar o consumidor Kafka. Encerrando servi√ßo.")
        await producer.stop()
        await cleanup_connections(pg_conn, mongo_client, redis_conn)
        return
    
    # Loop principal de processamento de eventos
    try:
        logger.info("üì° Aguardando mensagens...")
        async for msg in consumer:
            evento = msg.value
            logger.info(f"üì© Evento recebido: {evento.get('event_type')} (correlation_id: {evento.get('correlation_id', 'N/A')})")
            
            try:
                await processar_evento(evento, pg_conn, mongo_db, redis_conn, producer)
            except Exception as e:
                logger.error(f"‚ùå Erro ao processar evento: {e}")
                import traceback
                logger.error(traceback.format_exc())
    except Exception as e:
        logger.error(f"‚ùå Erro no loop principal: {e}")
    finally:
        logger.info("üõë Encerrando conex√µes...")
        await consumer.stop()
        await producer.stop()
        await cleanup_connections(pg_conn, mongo_client, redis_conn)

async def cleanup_connections(pg_conn, mongo_client, redis_conn):
    """Fecha todas as conex√µes com bancos de dados"""
    if pg_conn is not None:
        try:
            await pg_conn.close()
            logger.info("‚úÖ Conex√£o PostgreSQL encerrada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao fechar conex√£o PostgreSQL: {e}")
    
    if mongo_client is not None:
        try:
            mongo_client.close()
            logger.info("‚úÖ Conex√£o MongoDB encerrada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao fechar conex√£o MongoDB: {e}")
    
    if redis_conn is not None:
        try:
            await redis_conn.close()
            logger.info("‚úÖ Conex√£o Redis encerrada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao fechar conex√£o Redis: {e}")

# ========================
# üõ°Ô∏è API de Health Check
# ========================
async def health_check_api():
    """Endpoint de sa√∫de simples para verificar se o servi√ßo est√° funcionando."""
    async def health_handler(request):
        # Verificar conex√µes aqui, se necess√°rio
        return web.json_response({
            "service": "s2",
            "status": "healthy",
            "components": {
                "postgres": os.getenv("POSTGRES_HOST", "postgres"),
                "mongodb": os.getenv("MONGO_HOST", "mongo"),
                "redis": os.getenv("REDIS_HOST", "redis"),
                "kafka": os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092")
            },
            "timestamp": datetime.utcnow().isoformat()
        })
    
    app = web.Application()
    app.router.add_get('/health', health_handler)
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', 8000)
    await site.start()
    logger.info("‚úÖ API de health check iniciada na porta 8000")
    
    return runner

# ========================
# üöÄ Ponto de Entrada
# ========================
async def main():
    try:
        logger.info("üöÄ Iniciando servi√ßo S2 de processamento com persist√™ncia poliglota...")
        
        # Iniciar API de health check em uma task separada
        health_api_runner = await health_check_api()
        
        # Iniciar o processador
        await iniciar_processador()
        
        # Cleanup
        await health_api_runner.cleanup()
        
    except KeyboardInterrupt:
        logger.info("üëã Servi√ßo interrompido pelo usu√°rio")
    except Exception as e:
        logger.error(f"‚ùå Erro fatal: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("üëã Servi√ßo interrompido pelo usu√°rio")
    except Exception as e:
        logger.error(f"‚ùå Erro fatal: {e}")
        sys.exit(1)